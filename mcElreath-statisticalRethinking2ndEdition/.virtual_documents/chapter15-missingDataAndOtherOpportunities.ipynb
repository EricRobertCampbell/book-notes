


library(rethinking)
library(ggplot2)
library(dagitty)
library(cmdstanr)
library(posterior)

options(repr.plot.width = 14, repr.plot.height = 7)


data(WaffleDivorce)
d <- WaffleDivorce
head(d)


plot_df <- data.frame(
    d = d$Divorce,
    m = d$MedianAgeMarriage,
    lower = d$Divorce - d$Divorce.SE,
    upper = d$Divorce + d$Divorce.SE
)
ggplot(plot_df, aes(m, d)) +
    geom_point() +
    geom_errorbar(aes(ymin = lower, ymax = upper), width = 0) +
    labs(x = "Median Age Marriage", y = "Divorce Rate")





par(bg = 'white')
dag <- dagitty( 'dag {
D[latent]
e_D[latent]
A -> M -> D -> D_obs <- e_D
A -> D
}' )
drawdag(dag)





dlist <- list(
    D_obs = standardize(d$Divorce),
    D_sd = d$Divorce.SE / sd ( d$Divorce ),
    M = standardize(d$Marriage),
    A = standardize(d$MedianAgeMarriage),
    N = nrow(d)
)

m15.1 <- ulam(
    alist(
        D_obs ~ dnorm(D_true, D_sd),
        vector[N]:D_true ~ dnorm(mu, sigma),
        mu <- a + bA * A + bM * M,
        a ~ dnorm(0, 0.2),
        bA ~ normal(0, 0.5),
        bM ~ normal(0, 0.5),
        sigma ~ dexp(1)
    ),
    data = dlist,
    chains = 4,
    cores = 4
)


precis(m15.1, depth = 2)





par(bg = 'white')
dag <- dagitty( 'dag {
A
M[latent]
D
D[latent]
e_D[latent]
M_obs
e_M[latent]
A -> M -> D -> D_obs <- e_D
A -> D
M -> M_obs <- e_M
}' )
drawdag(dag)





dlist <- list(
    D_obs = standardize(d$Divorce),
    D_sd = d$Divorce.SE / sd ( d$Divorce ),
    M_obs = standardize(d$Marriage),
    M_sd = d$Marriage.SE / sd ( d$Marriage ),
    A = standardize(d$MedianAgeMarriage),
    N = nrow(d)
)

m15.2 <- ulam(
    alist(
        D_obs ~ dnorm(D_true, D_sd),
        vector[N]:D_true ~ dnorm(mu, sigma),
        mu <- a + bA * A + bM * M_true[i],
        M_obs ~ dnorm(M_true, M_sd),
        vector[N]:M_true ~ dnorm(0, 1),
        a ~ dnorm(0, 0.2),
        bA ~ normal(0, 0.5),
        bM ~ normal(0, 0.5),
        sigma ~ dexp(1)
    ),
    data = dlist,
    chains = 4,
    cores = 4
)


precis(m15.2, depth = 2)





par(bg = 'white')
dag <- dagitty( 'dag {
A[pos="0,0"]
M[latent,pos="1,-1"]
M_obs[pos="2,-1"]
D[latent,pos="1,1"]
D_obs[pos="2,1"]
e_D[latent,pos="3,1"]
e_M[latent,pos="3,-1"]
P[pos="4,0"]
A -> M -> D -> D_obs <- e_D
A -> D
M -> M_obs <- e_M
e_M <- P -> e_D
}' )
drawdag(dag)





par(bg = 'white')
dag <- dagitty( 'dag {
A[pos="0,0"]
M[latent,pos="1,-1"]
M_obs[pos="2,-1"]
D[latent,pos="1,1"]
D_obs[pos="2,1"]
e_D[latent,pos="3,1"]
e_M[latent,pos="3,-1"]
A -> M -> D -> D_obs <- e_D
A -> D
M -> M_obs <- e_M
M -> e_D
}' )
drawdag(dag)





par(bg = 'white')
dag <- dagitty( 'dag {
e_A[latent, pos="0,0"]
A_obs[pos="1,0"]
A[pos="2,0"]
M[pos="3,-1"]
D[pos="3,1"]
e_A -> A_obs <- A -> D
A -> M
}' )
drawdag(dag)





N <- 500
A <- rnorm(N)
M <- rnorm(N, -A)
D <- rnorm(N, A)
A_obs <- rnorm(N, A)





N <- 100
S <- rnorm(N)
H <- rbinom(N, size=10, inv_logit(S))





par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
S -> H
H -> H_star
H_star <- D
}' )
drawdag(dag)
# a)


par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
S -> H
H -> H_star
H_star <- D
S -> D
}' )
drawdag(dag)
# b)


par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
X[latent,pos="0.5,0.5"]
S -> H
H -> H_star
H_star <- D
D <- X -> H
}' )
drawdag(dag)
# c)


par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
S -> H
H -> H_star
H_star <- D
H -> D
}' )
drawdag(dag)
# c)





D <- rbern(N)
Hm <- H # this is H^*
Hm[D==1] <- NA





D <- ifelse(S > 0, 1, 0)
Hm <- H
Hm[D==1] <- NA





set.seed(501)
N <- 1000
X <- rnorm(N)
S <- rnorm(N)
H <- rbinom(N, size = 10, inv_logit(2 + S - 2 * X))
D <- ifelse(X > 0, 1, 0)
Hm <- H
Hm[D==1] <- NA

data_list <- list(
    H = H,
    S = S
)

m15.3 <- ulam(
    alist(
        H ~ binomial(10, p),
        logit(p) <- a + bS * S,
        a ~ normal(0, 1),
        bS ~ normal(0, 0.5)
    ),
    data = data_list,
    chains = 4,
    cores = 4
)
precis(m15.3)





data_list_0 <- list(
    H = H[D==0],
    S = S[D==0]
)

m15.4 <- ulam(
    alist(
        H ~ binomial(10, p),
        logit(p) <- a + bS * S,
        a ~ normal(0, 1),
        bS ~ normal(0, 0.5)
    ),
    data = data_list_0,
    chains = 4,
    cores = 4
)
precis(m15.4)





N <- 1000
S <- rnorm(N)
H <- rbinom(N, size = 10, inv_logit(S))
D <- ifelse(H < 5, 1, 0)
Hm <- H
Hm[D==1] <- NA





par(bg = 'white')
dag <- dagitty( 'dag {
U[latent,pos="0,0"]
M[pos="-1,0"]
B[pos="1,0"]
K[pos="0,2"]
U -> M -> K <- B <- U
}' )
drawdag(dag)





par(bg = 'white')
dag <- dagitty( 'dag {
U[latent,pos="0,0"]
M[pos="-1,0"]
B[latent,pos="1,0"]
K[pos="0,2"]
B_M[pos="1, -1"]
R_B[pos="0,-1"]
U -> M -> K <- B <- U
R_B -> B_M <- B
}' )
drawdag(dag)


par(bg = 'white')
dag <- dagitty( 'dag {
U[latent,pos="0,0"]
M[pos="-1,0"]
B[latent,pos="1,0"]
K[pos="0,2"]
B_M[pos="1, -1"]
R_B[pos="0,-1"]
U -> M -> K <- B <- U
M -> R_B -> B_M <- B
}' )
drawdag(dag)


par(bg = 'white')
dag <- dagitty( 'dag {
U[latent,pos="0,0"]
M[pos="-1,0"]
B[latent,pos="1,0"]
K[pos="0,2"]
B_M[pos="1, -1"]
R_B[pos="0,-1"]
U -> M -> K <- B <- U
B -> R_B -> B_M <- B
}' )
drawdag(dag)






par(bg = 'white')
dag <- dagitty( 'dag {
U[latent,pos="0,0"]
M[pos="-1,0"]
B[latent,pos="1,0"]
K[pos="0,2"]
B_M[pos="2,0"]
R_B[pos="2,1"]
V[latent,pos="1.5,0.5"]
U -> M -> K <- B <- U
B_M <- B
B <- V -> R_B -> B_M
}' )
drawdag(dag)






data(milk)
d <- milk
d$neocortex.prop <- d$neocortex.perc / 100
d$logmass <- log(d$mass)
data_list <- list(
    K = standardize(d$kcal.per.g),
    B = standardize(d$neocortex.prop),
    M = standardize(d$logmass)
)

m15.5 <- ulam(
    alist(
        K ~ dnorm(mu, sigma),
        mu <- a + bB * B + bM * M,
        B ~ dnorm(nu, sigma_B),
        c(a, nu) ~ dnorm(0, 0.5),
        c(bB, bM) ~ dnorm(0, 0.5),
        sigma_B ~ dexp(1),
        sigma ~ dexp(1)
    ),
    data = data_list,
    chains = 4,
    cores = 4
)


precis(m15.5, depth = 2)





obs_idx <- which(!is.na(d$neocortex.prop))
dat_list_obs <- list(
    K = data_list$K[obs_idx],
    M = data_list$M[obs_idx],
    B = data_list$B[obs_idx]
)
m15.6 <- ulam(
    alist(
        K ~ dnorm(mu, sigma),
        mu <- a + bB * B + bM * M,
        B ~ dnorm(nu, sigma_B),
        c(a, nu) ~ dnorm(0, 0.5),
        c(bB, bM) ~ dnorm(0, 0.5),
        sigma_B ~ dexp(1),
        sigma ~ dexp(1)
    ),
    data = dat_list_obs,
    chains = 4,
    cores = 4
)


par(bg = 'white')
plot(coeftab(m15.5, m15.6), pars = c("bB", "bM"))





m15.7 <- ulam(
    alist(
        # K as a function of B and M
        K ~ dnorm(mu, sigma),
        mu <- a + bB * B_merge + bM * M,

        # M and B correlation
        MB ~ multi_normal(c(muM, muB), Rho_BM, Sigma_BM),
        matrix[29,2]:MB <<- append_col(M, B_merge),

        # define B_merge as a mix of observed and imputed values
        vector[29]:B_merge <- merge_missing(B, B_impute),

        # priors
        c(a, muM, muB) ~ dnorm(0, 0.5),
        c(bB, bM) ~ dnorm(0, 0.5),
        sigma ~ dexp(1),
        Rho_BM ~ lkj_corr(2),
        Sigma_BM ~ dexp(1)
    ),
    data = data_list,
    chains = 4,
    cores = 4
)
precis(m15.7, depth = 3)





data(Moralizing_gods)
str(Moralizing_gods)





table(Moralizing_gods$moralizing_gods, useNA = 'always')





Moralizing_gods$moralizing_gods_symbol <- as.character(Moralizing_gods$moralizing_gods)
Moralizing_gods$moralizing_gods_symbol[is.na(Moralizing_gods$moralizing_gods_symbol)] <- "NA"

ggplot(Moralizing_gods, aes(year, population)) +
    geom_point(aes(shape = factor(moralizing_gods_symbol), colour = factor(moralizing_gods_symbol))) +
    scale_shape_manual(values = c("1" = 16, "0" = 17, "NA" = 18))





with(Moralizing_gods, table(gods=moralizing_gods, literacy=writing, useNA = 'always'))





par(bg = 'white')
dag <- dagitty( 'dag {
P[pos="0,0"]
G[latent, pos="2,0"]
G_m[pos="4,0"]
R_G[pos="3,1"]
W[pos="1,1"]
G -> G_m <- R_G <- W <- P <- G
}' )
drawdag(dag)






haw <- which(Moralizing_gods$polity == "Big Island Hawaii")
columns <- c("year", 'writing', 'moralizing_gods')
t(Moralizing_gods[haw, columns])





par(bg = 'white')
dag <- dagitty( 'dag {
R_c[pos="0,0"]
C_s[pos="1,0"]
C[latent,pos="2,0"]
N[pos="3,0"]
R_c -> C_s <- C -> N
}' )
drawdag(dag)





set.seed(9)

N_houses <- 100L
alpha <- 5
beta <- -3
k <- 0.5
r <- 0.2
cat <- rbern(N_houses, k)
notes <- rpois(N_houses, alpha + beta * cat)
R_C <- rbern(N_houses, r)
cat_obs <- cat
cat_obs[R_C == 1] <- -9L # arbitrary value
dat <- list(
    notes = notes,
    cat = cat_obs,
    R_C = R_C,
    N = as.integer(N_houses)
)





m15.8 <- ulam(
    alist(
        # singing bird model
        # cat known present / absent
        notes|R_C == 0 ~ poisson(lambda),
        log(lambda) <- a + b * cat,
        # cat NA
        notes|R_C==1 ~ custom(log_sum_exp(
            log(k) + poisson_lpmf(notes | exp(a + b)),
            log(1 - k) + poisson_lpmf(notes | exp(a))
        )),

        # priors
        a ~ normal(0, 1),
        b ~ normal(0, 0.5),

        # sneaking cat model
        cat|R_C == 0 ~ bernoulli(k),
        k ~ beta(2, 2)
    ),
    data = dat,
    chains = 4,
    cores = 4
)





m15.9 <- ulam(
    alist(
        # singing bird model
        # cat known present / absent
        notes|R_C == 0 ~ poisson(lambda),
        notes|R_C==1 ~ custom(log_sum_exp(
            log(k) + poisson_lpmf(notes | exp(a + b)),
            log(1 - k) + poisson_lpmf(notes | exp(a))
        )),
        log(lambda) <- a + b * cat,
        # cat NA

        # priors
        a ~ normal(0, 1),
        b ~ normal(0, 0.5),

        # sneaking cat model
        cat|R_C == 0 ~ bernoulli(k),
        k ~ beta(2, 2),

        # generated quantities
        gq> vector[N]:PrC1 <- exp(lpC1) / (exp(lpC1) + exp(lpC0)),
        gq> vector[N]:lpC1 <- log(k) + poisson_lpmf(notes[i] | exp(a + b)),
        gq> vector[N]:lpC0 <- log(1 - k) + poisson_lpmf(notes[i] | exp(a))
    ),
    data = dat,
    chains = 4,
    cores = 4
)


precis(m15.9, depth = 2)














data(milk)
d <- milk
d$neocortex.prop <- d$neocortex.perc / 100
d$logmass <- log(d$mass)

# data_list <- list(
#     K = standardize(d$kcal.per.g),
#     # B = standardize(d$neocortex.prop),
#     B = d$neocortex.prop, # if we want this to be a proportion, we don't want to standardized it (z-score)
#     M = standardize(d$logmass)
# )
data_list <- list(
    K = standardize(d$kcal.per.g),
    # B = standardize(d$neocortex.prop),
    B = d$neocortex.prop, # if we want this to be a proportion, we don't want to standardized it (z-score)
    M = standardize(d$logmass)
)
print(data_list)

m15m2.test.imputation <- ulam(
    alist(
        K ~ dnorm(mu, sigma),
        mu <- a + bB * B + bM * M,
        B ~ beta(alpha_param, beta_param),
        c(alpha_param, beta_param) ~ gamma(1.0, 1.0),
        c(a, nu) ~ dnorm(0, 0.5),
        c(bB, bM) ~ dnorm(0, 0.5),
        sigma_B ~ dexp(1),
        sigma ~ dexp(1)
    ),
    data = data_list,
    chains = 4,
    cores = 4,
    constraints = list(B = "lower=0, upper=1")  # Ensures B stays in [0,1]
)

d_complete <- d[complete.cases(d), ]
complete_data_list <- list(
    K = standardize(d_complete$kcal.per.g),
    # B = standardize(d$neocortex.prop),
    B = d_complete$neocortex.prop, # if we want this to be a proportion, we don't want to standardized it (z-score)
    M = standardize(d_complete$logmass)
)

m15m2.test.complete <- ulam(
    alist(
        K ~ dnorm(mu, sigma),
        mu <- a + bB * B + bM * M,
        B ~ beta(alpha_param, beta_param),
        c(alpha_param, beta_param) ~ gamma(1.0, 1.0),
        c(a, nu) ~ dnorm(0, 0.5),
        c(bB, bM) ~ dnorm(0, 0.5),
        sigma_B ~ dexp(1),
        sigma ~ dexp(1)
    ),
    data = complete_data_list,
    chains = 4,
    cores = 4,
    constraints = list(B = "lower=0, upper=1")  # Ensures B stays in [0,1]
)





stancode(m15m2.test.complete)


stancode(m15m2.test.imputation)


imputed_data <- c(data_list, list(N = nrow(d), N_miss = sum(is.na(d$neocortex.prop)), B_missidx = which(is.na(d$neocortex.prop))))
# STAN doesn't like it when variable values are NA, so we're going to set any missing ones to -1. It shouldn't make a difference, since we're going to impute them anyway.
imputed_data$B[is.na(imputed_data$B)] <- -1
stancode <- "functions{
    vector merge_missing(array[] int miss_indexes , vector x_obs , vector x_miss) {
        int N = dims(x_obs)[1];
        int N_miss = dims(x_miss)[1];
        vector[N] merged;
        merged = x_obs;
        for ( i in 1:N_miss )
            merged[ miss_indexes[i] ] = x_miss[i];
        return merged;
    }
}
data{
     int N; // number of observations
     int N_miss; // number of missing values
     vector[N] K;
     vector[N] M;
     vector[N] B;
    array[N_miss] int B_missidx;
}
parameters{
     real<lower=0> beta_param;
     real<lower=0> alpha_param;
     real nu;
     real a;
     real bM;
     real bB;
     real<lower=0> sigma_B;
     real<lower=0> sigma;
     vector<lower=0, upper=1>[N_miss] B_impute;
}
model{
    vector[N] mu;
    vector[N] B_merge;
    sigma ~ exponential( 1 );
    sigma_B ~ exponential( 1 );
    bB ~ normal( 0 , 0.5 );
    bM ~ normal( 0 , 0.5 );
    a ~ normal( 0 , 0.5 );
    nu ~ normal( 0 , 0.5 );
    alpha_param ~ gamma(1.0, 1.0);
    beta_param ~ gamma(1.0, 1.0);
    B_impute ~ beta(1, 1);
    B_merge = merge_missing(B_missidx, to_vector(B), B_impute);
    B_merge ~ beta( alpha_param , beta_param );
    for ( i in 1:N ) {
        mu[i] = a + bB * B_merge[i] + bM * M[i];
    }
    K ~ normal( mu , sigma );
}
"
stancode_file <- write_stan_file(stancode)

model <- cmdstan_model(stancode_file)
fit <- model$sample(data = imputed_data, chains = 4, parallel_chains = 4)


posterior <- as_draws_matrix(fit)
head(posterior)


# TODO plot the existing and imputed B values
# TODO plot the old and new versions of Bb
imputed_draws <- posterior[, grep("B_impute", colnames(posterior))]

plot_df <- data.frame(index = seq_len(length(imputed_data$B)), B = imputed_data$B)
plot_df[plot_df$B == -1,]$B <- NA

missing_indices <- which(is.na(plot_df$B))
imputed_df <- data.frame(index = missing_indices, mean = rep(NA, length(missing_indices)), lower = rep(NA, length(missing_indices)), upper = rep(NA, length(missing_indices)))
# print(imputed_df)
current_imputed_index <- 1
for (i in 1:length(plot_df$B)) {
    if (is.na(plot_df$B[i])) {
        column <- imputed_draws[, current_imputed_index]
        imputed_df[imputed_df$index == i, 'lower'] <- quantile(column, 0.025)
        imputed_df[imputed_df$index == i, 'upper'] <- quantile(column, 0.975)
        imputed_df[imputed_df$index == i, 'mean'] <- mean(column)

        current_imputed_index <- current_imputed_index + 1
    }
}
ggplot() +
    geom_point(data = plot_df, mapping = aes(index, B), color = "blue") +
    geom_point(data = imputed_df, mapping = aes(index, mean), color = "red") +
    geom_errorbar(data = imputed_df, mapping = aes(x = index, ymin = lower, ymax = upper), width = 0) + 
    coord_cartesian(ylim = c(0, 1))





precis(fit)


par(bg = 'white')
plot(coeftab(m15.5, m15.6), pars = c("bB", "bM"))

quantile(posterior[, "bB"], c(0.025, 0.5, 0.975))
quantile(posterior[, "bM"], c(0.025, 0.5, 0.975))








data(WaffleDivorce)
d <- WaffleDivorce

dlist <- list(
    D_obs = standardize(d$Divorce),
    D_sd = d$Divorce.SE / sd ( d$Divorce ),
    M = standardize(d$Marriage),
    A = standardize(d$MedianAgeMarriage),
    N = nrow(d)
)

# this is m15.1
m15m3.standard_error <- ulam(
    alist(
        D_obs ~ dnorm(D_true, D_sd),
        vector[N]:D_true ~ dnorm(mu, sigma),
        mu <- a + bA * A + bM * M,
        a ~ dnorm(0, 0.2),
        bA ~ normal(0, 0.5),
        bM ~ normal(0, 0.5),
        sigma ~ dexp(1)
    ),
    data = dlist,
    chains = 4,
    cores = 4
)

dlist_doubled_error <- list(
    D_obs = standardize(d$Divorce),
    D_sd = 2 * d$Divorce.SE / sd ( d$Divorce ),
    M = standardize(d$Marriage),
    A = standardize(d$MedianAgeMarriage),
    N = nrow(d)
)
m15m3.doubled_error <- ulam(
    alist(
        D_obs ~ dnorm(D_true, D_sd),
        vector[N]:D_true ~ dnorm(mu, sigma),
        mu <- a + bA * A + bM * M,
        a ~ dnorm(0, 0.2),
        bA ~ normal(0, 0.5),
        bM ~ normal(0, 0.5),
        sigma ~ dexp(1)
    ),
    data = dlist_doubled_error,
    chains = 4,
    cores = 4
)


precis(m15m3.standard_error)
precis(m15m3.doubled_error)


par(bg = 'white')
plot(coeftab(m15m3.standard_error, m15m3.doubled_error), pars = c("a", "bA", "bM"))








NUM_POINTS <- 1e3
X <- rnorm(NUM_POINTS)
Y <- rnorm(NUM_POINTS, mean = X, sd = 1)
Z <- rnorm(NUM_POINTS, mean = Y + 1, sd = 1)

data_list <- list(
    N = NUM_POINTS,
    X = X,
    Y = Y,
    Z = Z
)
model_string <- "data {
    int N;
    vector[N] X;
    vector[N] Y;
    vector[N] Z;
}
parameters {
    real a;
    real bX;
    real bZ;
    real<lower=0> sigma;
}
model {
    bX ~ normal(0, 1);
    bZ ~ normal(0, 1);
    a ~ normal(0, 1);
    sigma ~ exponential(1);
    vector[N] mu = a + bX * X + bZ * Z;
    Y ~ normal(mu, sigma);
}
"
model_file <- write_stan_file(model_string)
m15m4 <- cmdstan_model(model_file)
m15m4_fit <- m15m4$sample(data = data_list, chains = 4, parallel_chains = 4)


precis(m15m4_fit)

par(bg = 'white')
plot(precis(m15m4_fit))








set.seed(9)

N_houses <- 100L
alpha <- 5
beta <- -3
k <- 0.5
r <- 0.2
cat <- rbern(N_houses, k)
notes <- rpois(N_houses, alpha + beta * cat)
R_C <- rbern(N_houses, r)
cat_obs <- cat
cat_obs[R_C == 1] <- -9L # arbitrary value
dat <- list(
    notes = notes,
    cat = cat_obs,
    R_C = R_C,
    N = as.integer(N_houses)
)
dat

# same as m15.9
m15m5.1 <- ulam(
    alist(
        # singing bird model
        # cat known present / absent
        notes|R_C == 0 ~ poisson(lambda),
        notes|R_C == 1 ~ custom(log_sum_exp(
            log(k) + poisson_lpmf(notes | exp(a + b)),
            log(1 - k) + poisson_lpmf(notes | exp(a))
        )),
        log(lambda) <- a + b * cat,
        # cat NA

        # priors
        a ~ normal(0, 1),
        b ~ normal(0, 0.5),

        # sneaking cat model
        cat|R_C == 0 ~ bernoulli(k),
        k ~ beta(2, 2),

        # generated quantities
        gq> vector[N]:PrC1 <- exp(lpC1) / (exp(lpC1) + exp(lpC0)),
        gq> vector[N]:lpC1 <- log(k) + poisson_lpmf(notes[i] | exp(a + b)),
        gq> vector[N]:lpC0 <- log(1 - k) + poisson_lpmf(notes[i] | exp(a))
    ),
    data = dat,
    chains = 4,
    cores = 4
)


m15m5.1.results <- precis(m15m5.1, depth = 2, pars = c("PrC1"))
df <- data.frame(m15m5.1.results)
# head(df)
# rownames(df)
# names(m15m5.1.results)
df <- df[R_C == 1,]
df


df$variable <- rownames(df)
df$actual_cat_present <- cat[R_C == 1]
df$difference <- df$mean - df$actual_cat_present


ggplot(df, aes(variable)) +
    geom_point(aes(y = actual_cat_present), color = "blue") +
    geom_point(aes(y = mean), color = "red") +
    geom_errorbar(aes(ymin = X5.5., ymax = X94.5.), width = 0)


ggplot(df, aes(variable)) +
    geom_point(aes(y = difference))


mean(df$difference)





m15m5.2 <- ulam(
    alist(
        # singing bird model
        # cat known present / absent
        notes|R_C == 0 ~ poisson(lambda),
        notes|R_C == 1 ~ custom(log_sum_exp(
            log(k) + poisson_lpmf(notes | exp(a + b)),
            log(1 - k) + poisson_lpmf(notes | exp(a))
        )),
        log(lambda) <- a + b * cat,
        # cat NA

        # priors
        a ~ normal(0, 1),
        b ~ normal(0, 0.5),

        # sneaking cat model
        cat|R_C == 0 ~ bernoulli(k),
        k ~ beta(1, 1),

        # generated quantities
        gq> vector[N]:PrC1 <- exp(lpC1) / (exp(lpC1) + exp(lpC0)),
        gq> vector[N]:lpC1 <- log(k) + poisson_lpmf(notes[i] | exp(a + b)),
        gq> vector[N]:lpC0 <- log(1 - k) + poisson_lpmf(notes[i] | exp(a))
    ),
    data = dat,
    chains = 4,
    cores = 4
)
m15m5.2.results <- precis(m15m5.2, depth = 2, pars = c("PrC1"))
df <- data.frame(m15m5.2.results)
# head(df)
# rownames(df)
# names(m15m5.1.results)
df <- df[R_C == 1,]
df$variable <- rownames(df)
df$actual_cat_present <- cat[R_C == 1]
df$difference <- df$mean - df$actual_cat_present

# actual vs. predicted probabilities
print(
    ggplot(df, aes(variable)) +
        geom_point(aes(y = actual_cat_present), color = "blue") +
        geom_point(aes(y = mean), color = "red") +
        geom_errorbar(aes(ymin = X5.5., ymax = X94.5.), width = 0)
)

# difference between actual and predicted probabilities
print(
    ggplot(df, aes(variable)) +
        geom_point(aes(y = difference))
)

print(mean(df$difference))











set.seed(100)

N <- 100
S <- rnorm(N)
H <- rbinom(N, size = 10, inv_logit(S))


# base model - just recover the values, not dealing with missing data at this point.
base_data <- list(
    S = S,
    H = H
)
m15m6.base <- ulam(
    alist(
        H ~ binomial(10, p),
        logit(p) <- a + bS * S,
        a ~ normal(0, 1),
        bS ~ normal(1, 1)
    ),
    data = base_data,
    chains = 4,
    cores = 4
)
results <- precis(m15m6.base, depth = 2)
print(results)
par(bg = 'white')
plot(results)





D <- rbern(N) # half the values are missing, totally at random
Hm <- H
Hm[D==1] <- NA


# missing_at_random_data <- list(
#     S = S,
#     H = Hm,
#     N_miss = length(which(is.na(Hm))),
#     miss_idx = which(is.na(Hm))
# )
# m15m6.1.model <- "
# functions {
#     vector merge_missing(array[] int miss_indexes ,vector x_obs , vector x_miss) {
#         int N = dims(x_obs)[1];
#         int N_miss = dims(x_miss)[1];
#         vector[N] merged;
#         merged = x_obs;
#         for (i in 1:N_miss)
#             merged[ miss_indexes[i] ] = x_miss[i];
#         return merged;
#     }
# }
# data {
#     int N;
#     int N_miss;
#     vector[N] S;
#     vector<lower=0, upper=10>[N] H;
#     array[N_miss] int<lower=0> miss_idx;
# }
# parameters {
#     real a;
#     real bS;
#     array[N_miss] int<lower=0, upper=10> H_impute;
# }
# model {
#     a ~ normal(0, 1);
#     bS ~ normal(1, 1);
#     vector[N] p = inv_logit(a + bS * S);
#     for (i in 1:N_miss) {
#         H_impute[i] ~ binomial(10, 0.5);
#     }
#     array[N] int H_merge = merge_missing(miss_idx, to_vector(H), H_impute);
#     H_merge ~ binomial(10, p);
# }"
# m15m6.1.file <- write_stan_file(m15m6.1.model)
# m15m6.1.stan_model <- cmdstan_model(m15m6.1.file)
# m15m6.1.fit <- m15m6.1.stan_model$sample(data = missing_at_random_data, chains = 4, parallel_chains = 4)
# # m15m6.1 <- ulam(
# #     alist(
# #         H ~ binomial(10, p),
# #         logit(p) <- a + bS * S,
# #         a ~ normal(0, 1),
# #         bS ~ normal(1, 1)
# #     ),
# #     data = missing_at_random_data,
# #     chains = 4,
# #     cores = 4
# # )
# results <- precis(m15m6.1.fit, depth = 2)
# print(results)
# par(bg = 'white')
# plot(results)





set.seed(100)

N <- 100
S <- rnorm(N)

# parameters for the beta
phi <- inv_logit(S)
lambda <- 6

alpha <- lambda * phi
beta <- lambda * (1 - phi)

H_orig <- rbinom(N, size = 10, inv_logit(S))
H <- 10 * rbeta(N, alpha, beta)

check_df <- data.frame(H_orig = H_orig, H = H)
ggplot(check_df) +
    geom_density(aes(H, colour = "H")) +
    geom_density(aes(H_orig, colour = "H_orig"))





# base model - just recover the values, not dealing with missing data at this point.
base_data <- list(
    N = length(S),
    H = H / 10 # normalize
)
m15m6.base.model <- "
data {
    int N;
    vector<lower=0, upper=10>[N] H;
}
parameters {
    real a;
    real bS;
    real lambda;
    vector[N] S;
}
model {
    S ~ std_normal();
    a ~ std_normal();
    bS ~ normal(1, 0.1);
    vector[N] phi = a + bS * inv_logit(S);
    lambda ~ normal(6, 1);
    vector[N] alpha_param = lambda * phi;
    vector[N] beta_param = lambda * (1 - phi);
    H ~ beta(alpha_param, beta_param);
}
"
m15m6.base.file <- write_stan_file(m15m6.base.model)
m15m6.base.stan_model <- cmdstan_model(m15m6.base.file)
m15m6.base.fit <- m15m6.base.stan_model$sample(data = base_data, chains = 4, parallel_chains = 4, adapt_delta = 0.95)
results <- precis(m15m6.base.fit, depth = 2)
print(results)
par(bg = 'white')
plot(results)


draws_df <- as_draws_df(m15m6.base.fit)
head(draws_df)
colnames(draws_df)


S_draws <- draws_df[, grep("S\\[.+\\]", colnames(draws_df))]

draw_means <- apply(S_draws, 2, mean)
lower <- apply(S_draws, 2, function(x) quantile(x, 0.025))
upper <- apply(S_draws, 2, function(x) quantile(x, 0.975))
vars <- colnames(S_draws)
S_df <- data.frame(actual = S, mean = draw_means, lower = lower, upper = upper, var = vars)
ggplot(S_df, aes(var)) +
    geom_point(aes(y = mean, colour = "Simulated")) +
    geom_point(aes(y = actual, colour = "Actual")) +
    geom_errorbar(aes(ymin = lower, ymax = upper))


par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
S -> H
H -> H_star
H_star <- D
}' )
drawdag(dag)
# a)





D <- rbern(N)
Hm <- H
Hm[D==1] <- NA

D <- rbern(N) # half the values are missing, totally at random
Hm <- H
Hm[D==1] <- NA









par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
S -> H
H -> H_star
H_star <- D
S -> D
}' )
drawdag(dag)





set.seed(100)

N <- 100
S <- rnorm(N)

# parameters for the beta
phi <- inv_logit(S)
lambda <- 6

alpha <- lambda * phi
beta <- lambda * (1 - phi)

H <- 10 * rbeta(N, alpha, beta)

D <- ifelse(S > 0, 1, 0) # everyone above average gets their homework eaten
Hm <- H
Hm[D==1] <- NA

dogs_eat_good_students_homework_data <- list(
    N = N,
    S = S,
    H = Hm,
    N_miss = length(which(is.na(Hm))),
    miss_idx = which(is.na(Hm))
)

m15m6.b.fit <- m15m6.base.stan_model$sample(data = dogs_eat_good_students_homework_data, chains = 4, parallel_chains = 4, adapt_delta = 0.95)
results <- precis(m15m6.b.fit, depth = 2)
print(results)
par(bg = 'white')
plot(results)


draws_df <- as_draws_df(m15m6.b.fit)
head(draws_df)
colnames(draws_df)


par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
X[latent,pos="0.5,0.5"]
S -> H
H -> H_star
H_star <- D
D <- X -> H
}' )
drawdag(dag)
# c)


par(bg = 'white')
dag <- dagitty( 'dag {
S[pos="0,0"]
H[latent,pos="1,0"]
H_star[pos="1,1"]
D[pos="0,1"]
S -> H
H -> H_star
H_star <- D
H -> D
}' )
drawdag(dag)
# d)





data(elephants)
d <- elephants
head(d)


m15h1.data <- list(
    N = nrow(d),
    age = d$AGE - mean(d$AGE),
    matings = d$MATINGS
)
m15h1.model <- "data {
    int N;
    vector[N] age;
    array[N] int<lower=0> matings;
}
parameters {
    real a;
    real bA;
}
model {
    bA ~ normal(1, 1);
    a ~ std_normal();
    vector[N] lambda;
    for (i in 1:N) {
        lambda[i] = inv_logit(a + bA * age[i]);
    }
    matings ~ poisson(lambda);
}
"
m15h1.file <- write_stan_file(m15h1.model)
m15h1.stan_model <- cmdstan_model(m15h1.file)
m15h1.fit <- m15h1.stan_model$sample(data = m15h1.data, chains = 4, parallel_chains = 4, adapt_delta = 0.99)
results <- precis(m15h1.fit)
par(bg = 'white')
plot(results)


print(c(min(m15h1.data$age), max(m15h1.data$age)))
print(mean(m15h1.data$age))
print(sd(m15h1.data$age))


m15h1.error.model <- "data {
    int N;
    vector[N] age;
    array[N] int<lower=0> matings;
}
parameters {
    vector[N] real_age;
    real a;
    real bA;
}
model {
    real_age ~ normal(0, 7); // roughly the distribution of ages in the sample
    age ~ normal(real_age, 5);
    bA ~ std_normal();
    a ~ std_normal();
    vector[N] lambda;
    for (i in 1:N) {
        lambda[i] = inv_logit(a + bA * real_age[i]);
    }
    matings ~ poisson(lambda);
}
"
m15h1.error.file <- write_stan_file(m15h1.error.model)
m15h1.error.stan_model <- cmdstan_model(m15h1.error.file)
m15h1.error.fit <- m15h1.error.stan_model$sample(data = m15h1.data, chains = 4, parallel_chains = 4, adapt_delta = 0.9999)
error_results <- precis(m15h1.error.fit)
par(bg = 'white')
plot(error_results)


m15h1.no_error_params <- as_draws_df(m15h1.fit)
m15h1.error_params <- as_draws_df(m15h1.error.fit)
head(m15h1.no_error_params)

plot_df <- data.frame(
    variable = character(),
    mean = numeric(),
    lower = numeric(),
    upper = numeric(),
    model = character()
)

relevant_params <- c('a', 'bA')

means <- apply(m15h1.no_error_params[, relevant_params], 2, mean)
lower <- apply(m15h1.no_error_params[, relevant_params], 2, function(x) quantile(x, 0.025))
upper <- apply(m15h1.no_error_params[, relevant_params], 2, function(x) quantile(x, 0.975))
plot_df <- rbind(plot_df, data.frame(
    variable = relevant_params,
    mean = means,
    lower = lower,
    upper = upper,
    model = "No Errors"
))
means <- apply(m15h1.error_params[, relevant_params], 2, mean)
lower <- apply(m15h1.error_params[, relevant_params], 2, function(x) quantile(x, 0.025))
upper <- apply(m15h1.error_params[, relevant_params], 2, function(x) quantile(x, 0.975))
plot_df <- rbind(plot_df, data.frame(
    variable = relevant_params,
    mean = means,
    lower = lower,
    upper = upper,
    model = "Errors"
))
plot_df$variable <- as.factor(plot_df$variable)
plot_df$model <- as.factor(plot_df$model)
plot_df


ggplot(plot_df, aes(variable, colour = model)) +
    geom_point(aes(y = mean)) +
    geom_errorbar(aes(ymin = lower, ymax = upper)) +
    scale_x_discrete()








m15h2.model <- "data {
    int N;
    vector[N] age;
    array[N] int<lower=0> matings;
}
parameters {
    vector[N] real_age;
    real a;
    real bA;
}
model {
    real_age ~ normal(0, 7); // roughly the distribution of ages in the sample
    age ~ normal(real_age, 10);
    bA ~ std_normal();
    a ~ std_normal();
    vector[N] lambda;
    for (i in 1:N) {
        lambda[i] = inv_logit(a + bA * real_age[i]);
    }
    matings ~ poisson(lambda);
}
"
m15h2.file <- write_stan_file(m15h2.model)
m15h2.stan_model <- cmdstan_model(m15h2.file)
m15h2.fit <- m15h2.stan_model$sample(data = m15h1.data, chains = 4, parallel_chains = 4, adapt_delta = 0.9999)
error_results <- precis(m15h2.fit)
par(bg = 'white')
plot(error_results)








set.seed(100)
x <- c(rnorm(10), NA)
y <- c(rnorm(10, x), 100)
d <- list(x = x, y = y)





m15h3.full.data <- d
m15h3.complete.data <- list(
    x = d$x[!is.na(d$x)],
    y = d$y[which(!is.na(d$x))]
)

m15h3.model.complete <- ulam(
    alist(
        y ~ normal(mu, sigma),
        mu <- a + b * x,
        a ~ normal(0, 100),
        b ~ normal(0, 100),
        sigma ~ exponential(1)
    ),
    chains = 4,
    data = m15h3.complete.data
)
complete_results <- precis(m15h3.model.complete)
print(complete_results)
par(bg = 'white')
plot(complete_results)


m15h3.model.full <- ulam(
    alist(
        y ~ normal(mu, sigma),
        mu <- a + b * x,
        x ~ normal(0, 1),
        a ~ normal(0, 100),
        b ~ normal(0, 100),
        sigma ~ exponential(1)
    ),
    chains = 4,
    data = m15h3.full.data
)
full_results <- precis(m15h3.model.full)
print(full_results)
par(bg = 'white')
plot(full_results)


par(bg = 'white')
pairs(m15h3.model.full)





df <- as.data.frame(m15h3.full.data)
print(ggplot(df, aes(x, y)) +
    geom_point())
print(ggplot(df, aes(x, y)) +
    geom_point() +
    coord_cartesian(y = c(0, 2))
    )








data(Primates301)
d <- Primates301
cc <- complete.cases(d$brain, d$body)
B <- d$brain[cc]
M <- d$body[cc]
B <- B / max(B)
M <- M / max(M)





Bse <- 0.1 * B
Mse <- 0.1 * M





data <- list(B = B, M = M)
m15.1 <- ulam(
    alist(
        B ~ dlnorm(mu, sigma),
        mu <- a + b * log(M),
        a ~ normal(0, 1),
        b ~ normal(0, 1),
        sigma ~ exponential(1)
    ),
    data = data
)
m15.1_results <- precis(m15.1)
print(m15.1_results)





start <- list(M_true = data$M, B_true = data$B)





error_data <- list(
    B_obs = B,
    M_obs = M,
    Bse = Bse,
    Mse = Mse,
    N = length(B)
)
print(error_data)


# TODO now add in the measurement error
# m15h4.1 <- ulam(
#     alist(
#         B_obs ~ normal(B_true, Bse),
#         vector[N]:B_true ~ dlnorm(mu, sigma),
#         mu <- a + b * log(M_true[i]),
#         vector[N]:M_obs ~ normal(M_true, Mse),
#         vector[N]:M_true ~ normal(0.5, 0.1), # prior for the true mass (standardized)
#         a ~ normal(0, 1),
#         b ~ normal(0, 1),
#         sigma ~ exponential(1)
#     ),
#     data = error_data,
#     start = list(
#         M_true = error_data$M_obs, 
#         B_true = error_data$B_obs
#     ),
#     constraints = list(mu = "lower=0")
# )
# precis(m15h4.1)
m15h4.1_specification <- "data {
    int N;
    vector[N] M_obs;
    vector[N] B_obs;
}
parameters {
    real a;
    real b;
    real sigma;
}
model {
    a ~ std_normal();
    b ~ std_normal();
    sigma ~ exponential(1);
    vector[N] mu = a + b * B_obs;
    M_obs ~ normal(mu, sigma);
    
}"

m15h4.1_file <- write_stan_file(m15h4.1_specification)
m15h4.1_model <- cmdstan_model(m15h4.1_file)
m15h4.1_fit <- m15h4.1_model$sample(
    data = error_data,
    chains = 4
)


precis(m15h4.1_fit)
par(bg = 'white')
plot(precis(m15h4.1_fit))


m15h4.2_specification <- "data {
    int N;
    vector[N] M_obs;
    vector[N] Mse;
    vector[N] B_obs;
    vector[N] Bse;
}
parameters {
    real a;
    real b;
    real sigma;
    vector[N] M_true;
    vector[N] B_true;
}
model {
    a ~ std_normal();
    b ~ std_normal();
    sigma ~ exponential(1);
    B_true ~ normal(0.5, 0.2);
    B_obs ~ normal(B_true, Bse);
    vector[N] mu = a + b * B_true;
    M_true ~ normal(mu, sigma);
    M_obs ~ normal(M_true, Mse);
}"

m15h4.2_file <- write_stan_file(m15h4.2_specification)
m15h4.2_model <- cmdstan_model(m15h4.2_file)
m15h4.2_fit <- m15h4.2_model$sample(
    data = error_data,
    chains = 4
)

m15h4.2_results <- precis(m15h4.2_fit)
print(m15h4.2_results)
par(bg = 'white')
plot(m15h4.2_results)


par(bg = 'white')
plot(m15.1_results)








data(Primates301)
d <- Primates301
colSums(is.na(d))





cc <- complete.cases(d$body)
M <- d$body[cc]
M <- M / max(M)
B <- d$brain[cc]
B <- B / max(B, na.rm = TRUE)
print(length(B))
print(sum(is.na(B)))





start <- list(B_impute = rep(0.5, 56))





missingness_plot_df <- data.frame(
    M = M,
    B = as.integer(is.na(B))
)

ggplot(missingness_plot_df, aes(M, B)) +
    geom_point()





missing_B_M <- M[which(is.na(B))]

ggplot() +
    geom_density(data = data.frame(M = M), mapping = aes(M, colour = "Mass")) +
    geom_density(data = data.frame(missing = missing_B_M), mapping = aes(missing, colour = "Missing B"))





par(bg = 'white')
dag <- dagitty( 'dag {
M[pos="0,0"]
B[latent,pos="1,0"]
B_star[pos="2,0"]
P[pos="3,0"]
M -> B
B -> B_star
B_star <- P
}' )
drawdag(dag)
# a)





ggplot(data.frame(M = M, B = B), aes(M, B)) +
    geom_point()


B_missidx <- which(is.na(B))
modified_B <- B
modified_B[B_missidx] <- -1 # to avoid issues with NA values in STAN
m15h5.data <- list(B = modified_B, M = M, N = length(B), B_missidx = B_missidx, N_miss = length(B_missidx))
# print(m15h5.data)
m15h5.model_specification <- "
functions {
    vector merge_missing(array[] int miss_indexes, vector x_obs, vector x_miss) {
        int N = dims(x_obs)[1];
        int N_miss = dims(x_miss)[1];
        vector[N] merged;
        merged = x_obs;
        for (i in 1:N_miss) {
            merged[miss_indexes[i]] = x_miss[i];
        }
        return merged;
    }
}
data {
    int N;
    int N_miss;
    vector<lower=0>[N] M;
    vector[N] B;
    array[N_miss] int B_missidx;
}
parameters {
    real a;
    real b;
    real <lower=1e-3> sigma;
    vector[N_miss] B_impute;
}
model {
    a ~ std_normal();
    b ~ std_normal();
    sigma ~ exponential(1);
    vector[N] mu = a + b * log(M);
    B_impute ~ normal(0.5, 0.2);
    vector[N] B_merge = merge_missing(B_missidx, to_vector(B), B_impute);
    B_merge ~ normal(mu, sigma);
}
"
m15h5.file <- write_stan_file(m15h5.model_specification)
m15h5.model <- cmdstan_model(m15h5.file)
m15h5.fit <- m15h5.model$sample(data = m15h5.data, chains = 4)


m15h5.result <- precis(m15h5.fit)
print(m15h5.result)
par(bg = 'white')
plot(m15h5.result)


# Complete Cases
B_missidx <- which(is.na(B))
modified_B <- B
modified_B <- modified_B[-B_missidx]
modified_M <- M[-B_missidx]
m15h5.complete_data <- list(B = modified_B, M = modified_M, N = length(modified_B), B_missidx = c(), N_miss = 0)
# print(m15h5.complete_data)
m15h5.complete_fit <- m15h5.model$sample(data = m15h5.complete_data, chains = 4)


m15h5.complete_results <- precis(m15h5.complete_fit)
print(m15h5.complete_results)
par(bg = 'white')
plot(m15h5.complete_results)





# get the draws for the imputed values and arrange them in a dataframe
draws <- as_draws_df(m15h5.fit)
imputed_draws <- draws[, grep('B_impute', colnames(draws))]
means <- apply(imputed_draws, 2, mean)
lower <- apply(imputed_draws, 2, function(x) quantile(x, 0.025))
upper <- apply(imputed_draws, 2, function(x) quantile(x, 0.975))
imputed_Ms <- M[B_missidx]
imputed_M_df <- data.frame(
    M = imputed_Ms,
    mean = means,
    lower = lower,
    upper = upper
)
ggplot() +
    geom_point(data = data.frame(M = M, B = B), mapping = aes(M, B)) +
    geom_point(data = imputed_M_df, mapping = aes(M, mean)) +
    geom_errorbar(data = imputed_M_df, mapping = aes(M, ymin = lower, ymax = upper))









spinner_data <- data.frame(
    value = 1:8,
    frequency = c(18, 19, 22, NA, NA, 19, 20, 22)
)

ggplot(spinner_data, aes(value, frequency)) +
    geom_bar(stat = 'identity')





no_missing_spinner_data <- spinner_data[-which(is.na(spinner_data$frequency)), ]
m15h7.no_missing_data <- list(
    N = nrow(no_missing_spinner_data),
    counts = no_missing_spinner_data$frequency
)
print(m15h7.no_missing_data)
m15h7.no_missing_model_specification <- "
data {
    int N;
    array[N] int counts;
}
parameters {
    simplex[N] theta;
}
model {
    theta ~ dirichlet(rep_vector(1, N));
    counts ~ multinomial(theta);
}
"

m15h7.no_missing_file <- write_stan_file(m15h7.no_missing_model_specification)
m15h7.no_missing_model <- cmdstan_model(m15h7.no_missing_file)
m15h7.no_missing_fit <- m15h7.no_missing_model$sample(data = m15h7.no_missing_data)


no_missing_results <- precis(m15h7.no_missing_fit, depth = 2)
print(no_missing_results)
par(bg = 'white')
plot(no_missing_results)





sum(spinner_data$frequency, na.rm = TRUE)








library(LaplacesDemon)
theta_sim <- rep(1, 8)
values <- rdirichlet(5, alpha = theta_sim)
print(max(values) / min(values))





theta_sim <- rep(100, 8)
values <- rdirichlet(1000, alpha = theta_sim)
print(max(values) / min(values))





m15h7.data <- list(
    N = nrow(no_missing_spinner_data),
    counts = no_missing_spinner_data$frequency
)
print(m15h7.data)
m15h7.model_specification <- "
data {
    int N; // existing
    array[N] int counts; // observed counts
}
parameters {
    simplex[N] theta;
    int N4;
    int N5;
}
transformed parameters {
    int N_total = N + 2;
}
model {
    N4 ~ poisson(20);
    N5 ~ poisson(20);

    // merge the observed counts and the imputed ones
    array[N] int merged_counts;
    for (i in 1:N) {
        merged_counts[i] = counts[i];
    }
    merged_counts[N + 1] = N4;
    merged_counts[N + 2] = N5;
    theta ~ dirichlet(rep_vector(100, N_total));
    total_counts ~ multinomial(theta);
}
"

m15h7.file <- write_stan_file(m15h7.model_specification)
m15h7.model <- cmdstan_model(m15h7.file)
m15h7.fit <- m15h7._model$sample(data = m15h7.data)






